{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzoBellomo/InformationRetrieval/blob/main/notebooks/4_SearchEngineWeaviate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Weaviate as a Search Engine"
      ],
      "metadata": {
        "id": "euSpBGPyWT2D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWhrBsKVeaI",
        "outputId": "618bc7b0-98a4-4461-a804-4e42d79bc4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.11.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (2.10.6)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.70.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.8.0->weaviate-client) (4.12.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading weaviate_client-4.11.0-py3-none-any.whl (350 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m350.1/350.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading grpcio_health_checking-1.70.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, protobuf, grpcio-tools, grpcio-health-checking, authlib, weaviate-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "Successfully installed authlib-1.3.1 grpcio-health-checking-1.70.0 grpcio-tools-1.70.0 protobuf-5.29.3 validators-0.34.0 weaviate-client-4.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U weaviate-client\n",
        "import weaviate\n",
        "import weaviate.classes.config as wc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from weaviate.classes.query import MetadataQuery\n",
        "from weaviate.classes.config import Configure, Property, DataType, Tokenization\n",
        "from weaviate.classes.query import Filter\n",
        "\n",
        "client = weaviate.connect_to_embedded()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfAKTpq7ZEvq",
        "outputId": "542f7407-3208-469f-c5f9-5f83adb66c74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Binary /root/.cache/weaviate-embedded did not exist. Downloading binary from https://github.com/weaviate/weaviate/releases/download/v1.26.6/weaviate-v1.26.6-Linux-amd64.tar.gz\n",
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a simple collection that has just one field of texts.  "
      ],
      "metadata": {
        "id": "IOwPipiL2Hu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestCollection\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"text\", data_type=wc.DataType.TEXT),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgtV0ZcfaFLK",
        "outputId": "2a780497-2fcb-4d48-9f68-74d73f9ef618"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec38b66110>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a list of simple documents that are useful to test some simple queries"
      ],
      "metadata": {
        "id": "cMoBaDVW7mic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = [\n",
        "    {\"text\": \"Trump u.s.a. NATO\"},\n",
        "    {\"text\": \"trump usa N.A.T.O.\"},\n",
        "    {\"text\": \"trump u s a NATO\"},\n",
        "    {\"text\": \"the cat sleeps\"},\n",
        "    {\"text\": \"u are a star\"}\n",
        "]"
      ],
      "metadata": {
        "id": "Nnq7T9l_eO6I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create the collection and we insert the samples"
      ],
      "metadata": {
        "id": "iG_xXKqf8ADR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestCollection\")\n",
        "for doc in sample_docs:\n",
        "    documents.data.insert(doc)"
      ],
      "metadata": {
        "id": "sXQi9K3peTUr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is how to iterate over all documents in the collection"
      ],
      "metadata": {
        "id": "uGS1C5Be8Dk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the elements\n",
        "for doc in documents.iterator():\n",
        "  print(doc.uuid, \" - \", doc.properties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGxnrxb4eVou",
        "outputId": "f9c43ddb-dbf2-444c-b808-3c23abff9898"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2c9eb6ac-a3dd-429a-9a9e-d7b2091033b8  -  {'text': 'the cat sleeps'}\n",
            "7c1422fe-bb47-44c5-b940-d6f775b004b9  -  {'text': 'trump usa N.A.T.O.'}\n",
            "a17fe3ca-4d5b-4425-9a54-3f6569e39987  -  {'text': 'trump u s a NATO'}\n",
            "f2976550-d198-4f56-b77c-4da6631912c3  -  {'text': 'Trump u.s.a. NATO'}\n",
            "f3e29f0f-d3b2-45bb-8799-1457f4dbda85  -  {'text': 'u are a star'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try some simple queries, bm25 is the vectorization textual technique that we saw in lecture 2 (better than TFIDF). This means that the following query is processed textually."
      ],
      "metadata": {
        "id": "KxWBLZ_p8H4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"sleep\"\n",
        "response = documents.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"text\"]))"
      ],
      "metadata": {
        "id": "eTcpqOrchF3P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, words are not stemmed, but are lowercased. This is on the roadmap of features that Weaviate plans to support in the future.\n",
        "\n",
        "Let's also define a function that properly prints the results of a query"
      ],
      "metadata": {
        "id": "5wxC57Ws3bmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_query_results(query, prop_name, collection):\n",
        "  print(\"QUERY:: {}\\n\".format(query))\n",
        "  response = collection.query.bm25(query=query, return_metadata=MetadataQuery(score=True))\n",
        "  for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[prop_name]))"
      ],
      "metadata": {
        "id": "wBdt5xgtnjlQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"TRUMP\", \"text\", documents) #the words are lowercased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE7w1qQcpDYH",
        "outputId": "0866e7ba-73c6-4d94-ebd0-18a06d7c826e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: TRUMP\n",
            "\n",
            "0.24 - Trump u.s.a. NATO\n",
            "0.24 - trump u s a NATO\n",
            "0.22 - trump usa N.A.T.O.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"Trump\", \"text\", documents) #the words are lowercased"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEGcR_9ru5b0",
        "outputId": "0480e1dc-4730-4d19-e9e4-7412c40d8fec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: Trump\n",
            "\n",
            "0.24 - Trump u.s.a. NATO\n",
            "0.24 - trump u s a NATO\n",
            "0.22 - trump usa N.A.T.O.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"the\", \"text\", documents) # the stopwords are not present by assuming English"
      ],
      "metadata": {
        "id": "WwXKRsdmoQU7",
        "outputId": "ee543a61-a42a-4e5c-810b-fbc00a9b2090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: the\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we define a function that shows some very basic queries, but that are able"
      ],
      "metadata": {
        "id": "Q6mdSrWdEyJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def example_queries(prop_name, collection):\n",
        "    queries = [\"She is sleeping\", \"I sleep\", \"the usa\", \"I live in the u.s.a.\", \"TRUMP\"]\n",
        "    for query in queries:\n",
        "      print_query_results(query, prop_name, collection)\n",
        "      print(\"===============================================================\")\n",
        "      print()"
      ],
      "metadata": {
        "id": "5v40DKENuXXP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_docs)\n",
        "print(\"\\n\")\n",
        "example_queries(\"text\", documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AizK-RtvMK1",
        "outputId": "41b69079-2835-45a6-8ae0-7b22fc9c20d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'Trump u.s.a. NATO'}, {'text': 'trump usa N.A.T.O.'}, {'text': 'trump u s a NATO'}, {'text': 'the cat sleeps'}, {'text': 'u are a star'}]\n",
            "\n",
            "\n",
            "QUERY:: She is sleeping\n",
            "\n",
            "===============================================================\n",
            "\n",
            "QUERY:: I sleep\n",
            "\n",
            "===============================================================\n",
            "\n",
            "QUERY:: the usa\n",
            "\n",
            "0.56 - trump usa N.A.T.O.\n",
            "===============================================================\n",
            "\n",
            "QUERY:: I live in the u.s.a.\n",
            "\n",
            "0.62 - Trump u.s.a. NATO\n",
            "0.62 - trump u s a NATO\n",
            "0.26 - u are a star\n",
            "===============================================================\n",
            "\n",
            "QUERY:: TRUMP\n",
            "\n",
            "0.24 - Trump u.s.a. NATO\n",
            "0.24 - trump u s a NATO\n",
            "0.22 - trump usa N.A.T.O.\n",
            "===============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But how is the input really treated? How is it tokenized?"
      ],
      "metadata": {
        "id": "ngL4ck8knvWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TOKENIZATION OPTIONS**\n",
        "* word: alphanumeric, lowercased tokens (default tokenizer for Weaviate)\n",
        "* lowercase: lowercased tokens\n",
        "* whitespace: whitespace-separated, case-sensitive tokens\n",
        "* the entire value of the property is treated as a single token"
      ],
      "metadata": {
        "id": "UhCVDKEesasg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.create(\n",
        "    name=\"TestWhitespace\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"text\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WHITESPACE),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g7tFtA4pKCu",
        "outputId": "298d98fc-c853-4a42-ad92-38984f3fdfac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec38ca9b90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestWhitespace\")\n",
        "for doc in sample_docs:\n",
        "    documents.data.insert(doc)"
      ],
      "metadata": {
        "id": "0Th4Vhmgrxgh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"the\", \"text\", documents) # stopword is found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-PmaFTor1uj",
        "outputId": "647088ac-70e8-4124-de3c-f872db1ef363"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: the\n",
            "\n",
            "0.68 - the cat sleeps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"Trump\", \"text\", documents) # no lowercasing, thus not find \"trump\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vL3VsWn9r9HL",
        "outputId": "fa016a8e-e8d1-4ff6-8abf-c3c2235bdae8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: Trump\n",
            "\n",
            "0.68 - Trump u.s.a. NATO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"TRUMP\", \"text\", documents) # no lowercasing, thus not find \"trump\" and \"Trump\""
      ],
      "metadata": {
        "id": "VpwjVMemsIT8",
        "outputId": "95759c72-e4a3-44b2-8100-32bfa2d7969a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: TRUMP\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"u\", \"text\", documents) # whitespace does not split \"u.s.a.\" which is one token"
      ],
      "metadata": {
        "id": "8ZT4JgrvLt1h",
        "outputId": "7adab8ff-0526-48d0-d035-13cd6812f88a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: u\n",
            "\n",
            "0.38 - u are a star\n",
            "0.34 - trump u s a NATO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"u.s.a.\", \"text\", documents)"
      ],
      "metadata": {
        "id": "BIM1CoqMMLKm",
        "outputId": "9cf39b11-c4be-4e61-be6a-6f022f38e031",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: u.s.a.\n",
            "\n",
            "0.68 - Trump u.s.a. NATO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_queries(\"text\", documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbHBGl2bvPuS",
        "outputId": "de4c325e-bca2-45b9-fdf8-e19d610f1270"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: She is sleeping\n",
            "\n",
            "===============================================================\n",
            "\n",
            "QUERY:: I sleep\n",
            "\n",
            "===============================================================\n",
            "\n",
            "QUERY:: the usa\n",
            "\n",
            "0.68 - trump usa N.A.T.O.\n",
            "0.68 - the cat sleeps\n",
            "===============================================================\n",
            "\n",
            "QUERY:: I live in the u.s.a.\n",
            "\n",
            "0.68 - Trump u.s.a. NATO\n",
            "0.68 - the cat sleeps\n",
            "===============================================================\n",
            "\n",
            "QUERY:: TRUMP\n",
            "\n",
            "===============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Properties\n",
        "Let's now add some simple properties to our index. As of now we only handled the \"text\" property, containing some simple textual snippets."
      ],
      "metadata": {
        "id": "tSMMbB6pv62B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/5articles.json\n",
        "import json\n",
        "\n",
        "with open(\"5articles.json\", 'r') as f:\n",
        "  articles = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZUJtk6rsuBs",
        "outputId": "8b068dd7-2742-4309-ec53-2c0e190de146"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-27 15:39:48--  https://raw.githubusercontent.com/LorenzoBellomo/InformationRetrieval/refs/heads/main/data/5articles.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12566 (12K) [text/plain]\n",
            "Saving to: ‘5articles.json’\n",
            "\n",
            "5articles.json      100%[===================>]  12.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-27 15:39:48 (101 MB/s) - ‘5articles.json’ saved [12566/12566]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weUDmEkZ4KTp",
        "outputId": "1f3988bd-5896-4ad3-f673-642150839c45"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'American Airlines orders 60 Overture supersonic jets',\n",
              " 'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\",\n",
              " 'date': '2022-08-18',\n",
              " 'source': 'The New York Times'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.create(\n",
        "    name=\"TestProperties\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5CxLCKTxN6B",
        "outputId": "b4b0532a-756a-4cf2-d129-b90610dcd261"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec3844c510>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestProperties\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"]})"
      ],
      "metadata": {
        "id": "DNkz2jQVyQyI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents.iterator():\n",
        "  print(doc.uuid, \" - \", doc.properties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjhsGZXDycGz",
        "outputId": "9b484383-550c-47d6-b499-68e4d87a6ee6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4cfa5cc5-6fa2-43b4-abcf-b4ecf98b7955  -  {'maintext': 'Hamid Sanambar\\nGardai are hunting for a gunman who opened fire on a car in north Dublin - just metres from where Hamid Sanambar was gunned down last week.\\nEmergency services were alerted to reports of gunfire in Kilmore Road in the Artane area of the capital shortly before 9pm on Wednesday.\\nGardai believe a number of rounds were fired at the car before the gunman and the vehicle fled the scene.\\nFled\\nDetectives investigating the shooting are probing if the gunman interacted with the car driver before he opened fire.\\nIt is understood the gunman fled the area on foot.\\nThe incident happened just a few hundred metres from Kilbarron Avenue where Sanambar (41) was shot dead on Wednesday of last week.\\nGardai said investigations into that shooting are still ongoing.\\n\"Gardai are investigating reports of an alleged shooting incident on the Kilmore Road, Artane, Dublin 5,\" a spokeswoman said.\\n\"The incident occurred on June 5, 2019, at approximately 8.50pm.\\n\"No injuries were reported and investigations are ongoing.\"\\nThe area has been plagued by a number of gun attacks in recent weeks, including two murders.\\nA third person from the suburb, Sean Little (22), was shot dead in Balbriggan last month.\\nEarlier this week, Justice Minister Charlie Flanagan visited Coolock in north Dublin amid escalating gangland violence.\\nMr Flanagan repeatedly described the youngsters involved in the violence as \"losers\".\\nHe encouraged young people in the area to \"forget about the bling\".\\nDRUGS\\n\"My message to young people in this area is that there is no future in organised crime or drugs or the associated bling that that brings,\" he told the media as he arrived at Coolock Garda Station.\\n\"These are losers and I\\'m calling on the community to work closely with gardai to ensure that the challenge can be surmounted.\"\\nThe minister said there were about 100 people are involved in serious crime in the Coolock area.', 'title': 'Gunman opens fire on car just metres from scene of Hamid Sanambar murder'}\n",
            "542d7f9d-600c-4241-940e-95e2c313159c  -  {'maintext': \"The revival of supersonic passenger travel, thought to be long dead with the demise of Concorde nearly two decades ago, could be about to take wing as American Airlines has put in an order for 60 aircraft capable of flying at 1.7 times the speed of sound. \\nBoom is a start-up based in Denver, Colorado, whose development of Overture, an ultra-fast successor to Concorde that seats 65 to 88 passengers, is so advanced that it showed off designs at last month's Farnborough air show.\", 'title': 'American Airlines orders 60 Overture supersonic jets'}\n",
            "68fd626a-9b73-433f-bf7e-a2ab4041dd2a  -  {'maintext': 'Charles Leclerc\\nCharles Leclerc registered the maiden win of his Formula One career after romping to victory at the Belgian Grand Prix.\\nLess than 24 hours after Leclerc\\'s French motor racing contemporary, Anthoine Hubert, was killed at the Spa-Francorchamps venue, the young Monegasque driver delivered a dominant display to take the chequered flag in his friend\\'s honour.\\nLewis Hamilton finished second after fighting his way past Sebastian Vettel with 12 laps remaining.\\nHamilton\\'s Mercedes team-mate Valtteri Bottas also managed to see off Vettel after the Ferrari driver was forced to make an additional stop for tyres.\\nHamilton extended his lead over Bottas in the championship to 65 points.\\n\"This one is for Anthoine,\" said an emotional Leclerc on the radio.\\n\"It feels good but it is difficult to enjoy a weekend like this.\\n\"On one hand I have realised a dream, but on the other hand it has been a difficult weekend.\\n\"I have lost a friend, so I would like to dedicate my win to him.\\n\"We have grown up together. It is a shame what happened yesterday, so I cannot enjoy my first victory.\"\\nLeclerc posted a childhood picture with his arm around Hubert upon news of his death following a horrifying 257kmh crash in Saturday\\'s Formula Two race.\\nHe accompanied the picture with the words: \"I can\\'t believe it.\"\\nThe Ferrari driver, who is 22 next month, the same age as Hubert, was visibly moved by the tragedy.\\nPrior to the race, he hugged Hubert\\'s mother, Nathalie.\\nA moment of silence was observed before the race in the French driver\\'s memory. Nathalie held her son\\'s pink and white crash helmet. Hubert\\'s brother, Victhor, stood alongside her as the Formula One and grieving Formula Two drivers formed an arc, bowing their heads in honour of their fallen colleague.\\nAll 20 of the drivers\\' cars yesterday were adorned with \"Racing for Anthoine\" stickers.', 'title': 'Leclerc dedicates win to Hubert'}\n",
            "8aab2a7e-c0bb-4a41-88e6-b1be29a603a8  -  {'title': \"'One-punch killer's sentence will make others think twice'\", 'maintext': 'Luke O\\'Reilly with his mother Janet O\\'Brien Luke O\\'Reilly Jack Hall Ellis The Metro One Bar in Tallaght, where Hall Ellis had earlier accused Luke O\\'Reilly of talking to his girlfriend\\nThe mother of a young Dublin man who lost his life following a one-punch attack hopes the sentence her son\\'s killer was handed down will act as a deterrent for others.\\nJack Hall Ellis (21) was yesterday jailed for five years after pleading guilty to the manslaughter of Luke O\\'Reilly in Tallaght almost two years ago.\\nHall Ellis, who was on bail at the time over an alleged violent disorder incident, struck the 20-year-old with a single punch, which resulted in Mr O\\'Reilly hitting his head on the ground and suffering fatal injuries.\\nJudge Melanie Greally remarked that single-punch assaults leading to traumatic brain injuries are recurring on the courts\\' case load.\\nLast night, Mr O\\'Reilly\\'s mother, Janet O\\'Brien, told the Herald she was satisfied the judge recognised that such serious assaults were being carried out regularly.\\n\"If he didn\\'t get that punch he would never have hit the ground and died,\" Ms O\\'Brien said.\\nDeterrent\\n\"I was pleased the judge recognised the fact that there are so many of these one-punch attacks. I don\\'t know how many I have heard of since Luke, or parents who have got in touch that have been there before me.\"\\nMr O\\'Reilly\\'s mother described the five-year term given to Hall Ellis as \"a realistic sentence\" and added that, as a result, he would not simply walk away from the killing.\\n\"Hopefully it will make people sit up and listen, and they\\'ll think twice. It will act as a deterrent for kids going around trying to act the hard man, because as I said it doesn\\'t make much difference to us now,\" she added.\\nOn Halloween night in 2017, Mr O\\'Reilly was socialising in the Metro One Bar in Tallaght when Hall Ellis approached him and accused Luke of talking to his girlfriend.\\nEarly the following morning, Mr O\\'Reilly was walking along the Old Blessington Road when he was punched once from behind by Hall Ellis, who had drunk up to 20 shots on the night of the attack.\\nThe victim fell to the ground and hit his head on the concrete pavement. He suffered traumatic brain injuries and tragically passed away 13 days later at Beaumont Hospital.\\nIn a moving victim impact statement, Mr O\\'Reilly\\'s mother said that her family would never be the same following her son\\'s death.\\n\"No family occasion will ever be 100pc joyous again. Every birthday, seasonal holiday or any occasion is just a reminder that Luke\\'s not here to celebrate any of these with us. He should be here,\" Ms O\\'Brien said.\\nShe described how the birth of Luke, just after midnight on August 2, 1997, filled her life with \"unconditional love and unimaginable sense of pride\" that she would get to rear and guide his life so that he too could one day raise his own family.\\nThis, however, was taken away from Ms O\\'Brien by what she described as a \"cowardly\" attack by Hall Ellis.\\n\"I don\\'t believe Jack intended the outcome of his actions for Luke to lose his life, but ultimately this was the result of his actions.\\n\"I also believe that if Jack had abided by his bail conditions my son would be alive here with us today,\" she told the court, in reference to the fact that Hall Ellis had breached a curfew and a bond to keep the peace on the night of the fatal assault.\\nMs O\\'Brien also described as \"gut wrenching\" the fact that the accused presented himself to gardai only after he realised that Mr O\\'Reilly was not expected to survive.\\nShe recalled being informed by medical staff at Beaumont Hospital on the morning of November 13, 2017, that Mr O\\'Reilly was not going to recover from the assault, and making the decision to donate her son\\'s organs.\\n\"I climbed into bed beside him, hugging on to his warm body, never wanting to let go and listening to his beating heart that was now only beating to save someone else\\'s life,\" Ms O\\'Brien said.\\nJudge Greally said that Hall Ellis attributed his actions to anger and drunkenness, having previously heard that he consumed between seven and 10 double Captain Morgans that night.\\nThe court heard the accused had nine previous convictions, eight of which were for road traffic offences and one related to possession of drugs.\\nJudge Greally said she was handed a picture of Luke which she said was a \"poignant image\" of him in his youth, and that he was a \"special young man who was deeply loved by his family\".\\nSentencing Hall Ellis, the judge said the aggravating factors included the unprovoked nature of the assault, that he breached bail conditions on the night of the assault, and that even though he observed Luke motionless on the ground, he still decided to leave the scene.\\nShe gave him credit for his early guilty plea, his absence of previous violent conduct and his genuine remorse, before jailing him for seven years with the final two suspended.'}\n",
            "b2519277-6141-48cd-b500-1bd7d2150490  -  {'maintext': 'Antonio Conte. Pic: PA\\nHead coach Antonio Conte does not think Chelsea are in the race to sign Arsenal forward Alexis Sanchez.\\nSanchez is out of contract this summer and seemed certain to join Manchester City this month.\\nBut the Premier League leaders on Monday evening decided to end their interest because of the costs involved, with Manchester United in pole position, while there were suggestions the Premier League champions were also in the running.\\nConte last Friday spoke of his admiration for Sanchez and described any potential cut-priced deal for the Chile striker as a great opportunity.\\nThe Italian was evasive when quizzed on Chelsea\\'s interest in the player, taking his usual stance in deferring matters of recruitment to the club.\\nAsked if Chelsea were actively seeking to sign Sanchez, Conte said: \"I don\\'t know. I don\\'t think so. I don\\'t know, but I don\\'t think so.\"\\nConte, speaking ahead of tonight\\'s FA Cup third-round replay at home to Norwich, was reluctant to discuss the transfer market.\\n\"About the transfer market, I prefer to talk to the club, also to give opinions,\" he added.\\nPlanned\\n\"I repeat: I don\\'t want to give my opinion about the transfer market.\"\\nMeanwhile, Daniel Farke says Norwich will have something \"special\" planned for Chelsea tonight.\\nThe Canaries head to Stamford Bridge on the back holding the Premier League champions to a goalless draw at Carrow Road.\\nFarke\\'s men followed that up with a battling 1-0 win at Sky Bet Championship promotion hopefuls Bristol City, who earned great plaudits for their League Cup efforts against Manchester City.\\nThe German believes Norwich will have a free shot at pulling off a shock result in tonight trip to west London and see the winners at home to Newcastle in round four.\\n\"I\\'m hoping for another brilliant performance against one of the giants, and we\\'ll have a special plan for tomorrow,\" Farke said. \"Hopefully with a really good performance and, if Chelsea aren\\'t at their very best, then we\\'ll always have a chance.\\n\"It will be important to keep as much possession as possible, as we don\\'t want to be running after the ball for 90 minutes - so we have to be brave in our possession and our pressing.\"\\nFarke, though, accepts Norwich cannot afford to underestimate the challenge ahead.\\n\"They haven\\'t scored for three games so they will be wanting to show they can score, especially in a home match,\" the Canaries boss added.', 'title': \"Conte: 'Chelsea are not in the race to sign Sanchez'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"mother\", \"title\", documents) # prints the score and the title of the retrieved article"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ps9K8Nm4dlB",
        "outputId": "d6b3aeb2-9545-49ff-ebd9-53693b516f20"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: mother\n",
            "\n",
            "0.52 - 'One-punch killer's sentence will make others think twice'\n",
            "0.3 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"cars\", \"title\", documents) # There is no stemming, indeed, thus the next article is not returned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52N90QSJ7ymC",
        "outputId": "ebaba5b5-bfc2-454c-a656-0d1057474406"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: cars\n",
            "\n",
            "0.48 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"car\", \"title\", documents) # The score can be larger than 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86-0fUQa7xWz",
        "outputId": "981eef2e-2831-4012-e97f-f868c043037d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: car\n",
            "\n",
            "1.87 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Say that you now want to consider some words as \"stopwords\", that the system does not consider as such by default"
      ],
      "metadata": {
        "id": "5E7rUP8q7zmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_query_results(\"victory\", \"title\", documents) #As above, but below we classify it as a stopword\n",
        "\n",
        "documents.config.update(inverted_index_config=wc.Reconfigure.inverted_index(stopwords_additions=[\"victory\"]))\n",
        "\n",
        "print(\"\\n\")\n",
        "print_query_results(\"victory\", \"title\", documents)"
      ],
      "metadata": {
        "id": "rXGjsQRPM7c8",
        "outputId": "fd8b6470-2ded-4fd2-bc2b-3b5e4ce473c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUERY:: victory\n",
            "\n",
            "0.71 - Leclerc dedicates win to Hubert\n",
            "\n",
            "\n",
            "QUERY:: victory\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But fields in the query are not all \"born equal\". Some are more important than others (e.g., title). Let's boost the importance of the \"title\" field (by scaling its score count by two)"
      ],
      "metadata": {
        "id": "SeMtD7ct8mLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"BEFORE FIELD BOOSTING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMXZT4hh9qgy",
        "outputId": "2cf26ce9-cb96-4ec7-f143-b6ddd6c143ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FIELD BOOSTING: (query = race)\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    query_properties=[\"title^2\", \"maintext\"],\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"AFTER FIELD BOOSTING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1CjN-zP8tgF",
        "outputId": "f7353ebc-45ba-4c95-ceec-c355dc44c165"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFTER FIELD BOOSTING: (query = race)\n",
            "\n",
            "1.43 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The score is not double the score, because:\n",
        "- it is not using TF-IDF, but BM25 which scales slightly different\n",
        "- \"race\" is also present inside the maintext of the article"
      ],
      "metadata": {
        "id": "ghhZp_8dFPM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.objects[0].properties[\"maintext\"].count(\"race\") # indeed it appears once"
      ],
      "metadata": {
        "id": "9nGs1PzLEbrQ",
        "outputId": "3184656f-ed13-42bf-e234-cc8f68558945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add some basic filtering"
      ],
      "metadata": {
        "id": "j9idv4qXBmdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"BEFORE FILTERING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JSB97BWCQ70",
        "outputId": "6bbf6866-bc18-499c-af21-51b30ced9051"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FILTERING: (query = mother)\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=Filter.by_property(\"title\").contains_any([\"Leclerc\", \"formula\"]),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"AFTER FILTERING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYwQsYwXBnz7",
        "outputId": "da941948-2688-4b1c-e48d-e85522376539"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFTER FILTERING: (query = race)\n",
            "\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what happens when we also add dates as properties"
      ],
      "metadata": {
        "id": "W17t7sWGDkR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.create(\n",
        "    name=\"TestDate\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "        wc.Property(name=\"date\", data_type=wc.DataType.DATE)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_bGqfsdDn0z",
        "outputId": "90b841df-4fec-4698-e825-e1b213251861"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec38b9ba50>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[All property types](https://weaviate.io/developers/weaviate/config-refs/datatypes)"
      ],
      "metadata": {
        "id": "CY_I5yrgGBzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timezone, datetime\n",
        "documents = client.collections.get(\"TestDate\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"], \"date\": datetime.strptime(doc[\"date\"], \"%Y-%m-%d\").replace(tzinfo=timezone.utc)})"
      ],
      "metadata": {
        "id": "u9PTqqBhGlAG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents.iterator():\n",
        "  print(doc.uuid, \" - \", doc.properties['date'], '  ', doc.properties['title'])\n",
        "  # print(doc.uuid, \" - \", doc.properties)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjmLrEbsGXXr",
        "outputId": "ca5e9097-49b0-40dc-8456-a75c1ce16b6c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "650aa442-33a9-4511-a5a9-fa9bf411ef8c  -  2018-01-23 00:00:00+00:00    Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "8410ab1a-5780-43ff-a8e3-246730dfe17d  -  2019-06-07 00:00:00+00:00    Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "a35dc66b-bdd9-4997-aa5f-92a2132ba922  -  2019-06-29 00:00:00+00:00    'One-punch killer's sentence will make others think twice'\n",
            "e182cea0-1285-4277-a6e3-669b0e47dc6c  -  2019-09-01 00:00:00+00:00    Leclerc dedicates win to Hubert\n",
            "e8114e5c-6778-494d-96f2-067dbcc9d468  -  2022-08-18 00:00:00+00:00    American Airlines orders 60 Overture supersonic jets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"BEFORE FILTERING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Re1fWZ1IcOV",
        "outputId": "fc117242-8a3a-4b2b-e964-51f941d846f3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BEFORE FILTERING: (query = race)\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez' (2018-01-23 00:00:00+00:00)\n",
            "0.54 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(\n",
        "    query=\"race\",\n",
        "    filters=Filter.by_property(\"date\").greater_or_equal(datetime.strptime(\"2019-08-15\", \"%Y-%m-%d\").replace(tzinfo=timezone.utc)),\n",
        "    return_metadata=MetadataQuery(score=True)\n",
        ")\n",
        "print(\"AFTER FILTERING: (query = race)\\n\")\n",
        "for o in response.objects:\n",
        "    print(\"{} - {} ({})\".format(round(o.metadata.score*100)/100, o.properties[\"title\"], o.properties[\"date\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR4i3bKfJ9eJ",
        "outputId": "f2467b18-c0e4-4bcf-a019-49b7830835d0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AFTER FILTERING: (query = race)\n",
            "\n",
            "0.54 - Leclerc dedicates win to Hubert (2019-09-01 00:00:00+00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some advanced features, let's try some vectorized queries. Let's assume we want to find all articles that are \"related to sport\". In this current collection, \"sport\" is not present as a word in any title or maintext."
      ],
      "metadata": {
        "id": "-0oumORCKS3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "id": "uzryepW_KWFV"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's install some textual vectorizer to run some semantic search queries."
      ],
      "metadata": {
        "id": "-0S8Jz-0G0pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfortunately, we cannot use all the vectorizer modules that are present in Weaviate. Here is a list of the ones that are available\n",
        "client.get_meta()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9aIbtBRG80",
        "outputId": "982a0479-10c0-47f5-93f8-931c7afe6fcd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hostname': 'http://127.0.0.1:8079',\n",
              " 'modules': {'generative-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'Generative Search - OpenAI'},\n",
              "  'qna-openai': {'documentationHref': 'https://platform.openai.com/docs/api-reference/completions',\n",
              "   'name': 'OpenAI Question & Answering Module'},\n",
              "  'ref2vec-centroid': {},\n",
              "  'reranker-cohere': {'documentationHref': 'https://txt.cohere.com/rerank/',\n",
              "   'name': 'Reranker - Cohere'},\n",
              "  'text2vec-cohere': {'documentationHref': 'https://docs.cohere.ai/embedding-wiki/',\n",
              "   'name': 'Cohere Module'},\n",
              "  'text2vec-huggingface': {'documentationHref': 'https://huggingface.co/docs/api-inference/detailed_parameters#feature-extraction-task',\n",
              "   'name': 'Hugging Face Module'},\n",
              "  'text2vec-openai': {'documentationHref': 'https://platform.openai.com/docs/guides/embeddings/what-are-embeddings',\n",
              "   'name': 'OpenAI Module'}},\n",
              " 'version': '1.26.6'}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use COHERE as a textual vectorizer [https://dashboard.cohere.com/api-keys](https://dashboard.cohere.com/api-keys). As we can see, using colab we have only a few options for vectorization (openai, cohere, huggingface). Additionally, only one generation model is available (openai).\n",
        "Cohere provides free sample apis. OpenAI does not."
      ],
      "metadata": {
        "id": "2eb-2ivBTN8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## You need first to create a KEY !!!!\n",
        "from google.colab import userdata\n",
        "\n",
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_KEY') # MAKE SURE YOU CREATED A KEY\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n67v0q_ETPvy",
        "outputId": "7b1dbc82-5e23-4574-c9cb-a7c1e6c6c907"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 4184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HERE TO CHECK HOW TO INTEGRATE MODELS [https://weaviate.io/developers/weaviate/model-providers](https://weaviate.io/developers/weaviate/model-providers)"
      ],
      "metadata": {
        "id": "Df7kq_CvAljh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we create the example collection. Please note that we set here the vectorizer (cohere) and the generation module for an experiment that we will do later (openai, only availabe on the paid model)."
      ],
      "metadata": {
        "id": "e5NKdtCE8d6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wudqBaSsKtkJ",
        "outputId": "8a53fc1d-79d4-4a4a-9501-ffbf8fdfce02"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec702a0210>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"]}) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "c0EG-BXRNqof"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'sport'\\n\")\n",
        "response = documents.query.bm25(query=\"sport\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2281250c-ea20-4bc5-e810-49a3091f89e5",
        "id": "e3JPi_1RPNos"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'sport'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'sport'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"sport\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "id": "eVLWxgqCPNHP",
        "outputId": "c81e4738-abfb-4e66-b667-c51208d318ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'sport'\n",
            "\n",
            "0.61 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.65 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure syntactical search (ordered by decreasing similarity score): 'race'\\n\")\n",
        "response = documents.query.bm25(query=\"race\", return_metadata=MetadataQuery(score=True))\n",
        "for o in response.objects:\n",
        "    print(\"{} - {}\".format(round(o.metadata.score*100)/100, o.properties[\"title\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4uaK6uMN2Uk",
        "outputId": "05661d64-dd1d-40c0-86f2-5ff3c753d4f7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure syntactical search (ordered by decreasing similarity score): 'race'\n",
            "\n",
            "1.27 - Conte: 'Chelsea are not in the race to sign Sanchez'\n",
            "0.54 - Leclerc dedicates win to Hubert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pure vector search (ordered by increasing distance): 'race'\\n\")\n",
        "# NOTE THAT WE ALSO NEED THE PARAMETER DISTANCE\n",
        "response = documents.query.near_text(query=\"race\", return_metadata=MetadataQuery(score=True, distance=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} (score is {})\".format(round(o.metadata.distance*100)/100, o.properties[\"title\"], round(o.metadata.score*100)/100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnPc546bOJRn",
        "outputId": "786cca5f-b05f-4a0a-fb94-21770816c642"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pure vector search (ordered by increasing distance): 'race'\n",
            "\n",
            "0.61 - Leclerc dedicates win to Hubert (score is 0.0)\n",
            "0.61 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder (score is 0.0)\n",
            "0.69 - Conte: 'Chelsea are not in the race to sign Sanchez' (score is 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search (ordered by decreasing score): 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWxVaoXRLrh",
        "outputId": "6031d72f-9b8f-43a9-94a4-7d000f7c0a04"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search (ordered by decreasing score): 'race'\n",
            "0.59 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document 983e85a7-245d-4a1f-9abd-eb2d6bd78a5f: original score 1.2714014, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document 983e85a7-245d-4a1f-9abd-eb2d6bd78a5f: original score 0.31188643, normalized score: 0.09419514]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 0229274f-29f6-4575-bc1d-7412ca1b98a9: original score 0.5364737, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 0229274f-29f6-4575-bc1d-7412ca1b98a9: original score 0.3915854, normalized score: 0.5]\n",
            "0.48 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document b1bd8dae-f31d-430e-84ea-65a5eb114e53: original score 0.3867706, normalized score: 0.47548437]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Description of how scoring works](https://weaviate.io/developers/weaviate/concepts/search/hybrid-search)"
      ],
      "metadata": {
        "id": "ivXz0Sg1K9FU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A new method, RAG\n",
        "RAG stands for Retrieval Augmented Generation. This is a recent trend in Information Retrieval that aims at reducing the problem of \"hallucinations\" for Large Language Model generation, and returns better answers based on local document archives.\n",
        "- Traditional queries go as follows: the user makes a query to a search engine; the search engine returns, in some predefined format, the answer to that query.\n",
        "- LLM queries: the user makes a query to a Large Language Model (LLM); the LLM creates an answer based on the (often unspecified) training data that was originally used to train it. The LLM often hallucinates, returing wrong answers.\n",
        "- RAG: the user makes a query to a search engine; the search engine runs the query and gets its results. Before returning the results to the user, they are sent to a LLM to \"process\" and generate a textual response that is more convenient to read for the user, but (ideally) does not contain hallucinated information because they use precomputed (retrieved) results."
      ],
      "metadata": {
        "id": "6TXPYna2acie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to include some generative AI prompts to this query (let's add context to the entities in the news, or let's translate them in Italian).\n",
        "Note that this query will only work for those who have an openai paid module."
      ],
      "metadata": {
        "id": "EpjAkCt1SXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.close()\n",
        "cohere_key = userdata.get('COHERE_KEY')\n",
        "openai_key = userdata.get(\"OPENAI_KEY2\")\n",
        "headers = {\n",
        "    \"X-Cohere-Api-Key\": cohere_key,\n",
        "    \"X-OpenAI-Api-Key\": openai_key\n",
        "}\n",
        "client = weaviate.connect_to_embedded(headers=headers)"
      ],
      "metadata": {
        "id": "gFwUpSXl_15o",
        "outputId": "d107e632-9e0c-478b-f813-47c4c8a39b07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:weaviate-client:Started /root/.cache/weaviate-embedded: process ID 11228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.collections.delete_all()\n",
        "client.collections.create(\n",
        "    name=\"TestVectorizer\",\n",
        "    properties=[\n",
        "        wc.Property(name=\"maintext\", data_type=wc.DataType.TEXT, tokenization=Tokenization.WORD),\n",
        "        wc.Property(name=\"title\", data_type=wc.DataType.TEXT, tokenization=Tokenization.LOWERCASE),\n",
        "    ],\n",
        "    vectorizer_config=[\n",
        "        Configure.NamedVectors.text2vec_cohere(\n",
        "            name=\"maintext_vector\",\n",
        "            source_properties=[\"maintext\"],\n",
        "            #model=\"embed-multilingual-light-v3.0\"\n",
        "        )\n",
        "    ],\n",
        "    generative_config=Configure.Generative.openai(model=\"gpt-4\") # added generation module\n",
        ")"
      ],
      "metadata": {
        "id": "z1eqnNCPBGOo",
        "outputId": "88884b9e-6d2e-49d6-e5dc-69cbef4d6d0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weaviate.collections.collection.sync.Collection at 0x79ec39b5ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = client.collections.get(\"TestVectorizer\")\n",
        "for doc in articles:\n",
        "    documents.data.insert({\"maintext\": doc[\"maintext\"], \"title\": doc[\"title\"]}) # here weaviate performs the vectorization"
      ],
      "metadata": {
        "id": "AXmTMLjjBRcH"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = documents.generate.near_text(\n",
        "    query=\"sport\",  # The model provider integration will automatically vectorize the query\n",
        "    single_prompt=\"Write a short summary of maximum 100 characters in Italian of {maintext}\",\n",
        "    limit=2 # apply LLM to the top 2 results\n",
        ")"
      ],
      "metadata": {
        "id": "03LrtcpKBVgT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in response.objects:\n",
        "    print(obj.properties[\"title\"])\n",
        "    print(f\"Generated output: {obj.generated}\")  # Note that the generated output is per object\n",
        "    print(\"====================================================\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "ZuUsQBXRZpxA",
        "outputId": "f6751d67-d76c-4aad-f619-e70544bb935a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leclerc dedicates win to Hubert\n",
            "Generated output: Charles Leclerc ha ottenuto la sua prima vittoria in Formula Uno al Gran Premio del Belgio, dedicandola all'amico Anthoine Hubert, morto in un incidente.\n",
            "====================================================\n",
            "\n",
            "Gunman opens fire on car just metres from scene of Hamid Sanambar murder\n",
            "Generated output: La polizia cerca un uomo armato che ha sparato su un'auto a Dublino, vicino al luogo dove Hamid Sanambar è stato ucciso.\n",
            "====================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above implements RAG using an external LLM module (OpenAI), invoked via the internal Weaviate module. We can also implement a RAG by calling the LLM directly, by using Cohere to implement the vectorization (inside Weaviate) and the generation (direcly with an API call). This way we do not need to pay for an OpenAI API key."
      ],
      "metadata": {
        "id": "qT10gpOzk1pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "id": "HcS0hAhmCysG",
        "outputId": "857d4b14-ccd9-41f0-bd51-ac61c7d8e792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-5.13.12-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.0)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.13.12-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.13.12 fastavro-1.10.0 httpx-sse-0.4.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hybrid search: 'race'\")\n",
        "response = documents.query.hybrid(query=\"race\", alpha=0.5, return_metadata=MetadataQuery(score=True, explain_score=True), limit=3)\n",
        "for o in response.objects:\n",
        "  print(\"{} - {} [{}]\".format(round(o.metadata.score*100)/100, o.properties[\"title\"],  o.metadata.explain_score.strip().replace(\"\\n\", '')))"
      ],
      "metadata": {
        "id": "tFaZRSUxDPag",
        "outputId": "6acabc93-0966-4f66-87af-d363fa9ace79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hybrid search: 'race'\n",
            "0.59 - Conte: 'Chelsea are not in the race to sign Sanchez' [Hybrid (Result Set keyword,bm25) Document ad04ee5d-b50d-45a2-a0f5-002111e0d0c5: original score 1.2714014, normalized score: 0.5 - Hybrid (Result Set vector,hybridVector) Document ad04ee5d-b50d-45a2-a0f5-002111e0d0c5: original score 0.31191516, normalized score: 0.09438221]\n",
            "0.5 - Leclerc dedicates win to Hubert [Hybrid (Result Set keyword,bm25) Document 25062050-154b-49fd-aa58-cd219f6e6249: original score 0.5364737, normalized score: 0 - Hybrid (Result Set vector,hybridVector) Document 25062050-154b-49fd-aa58-cd219f6e6249: original score 0.39161777, normalized score: 0.5]\n",
            "0.48 - Gunman opens fire on car just metres from scene of Hamid Sanambar murder [Hybrid (Result Set vector,hybridVector) Document b43b5d85-8a63-431f-bb1b-8db57f93686c: original score 0.38678777, normalized score: 0.47541943]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "\n",
        "co = cohere.ClientV2(api_key=cohere_key)\n",
        "res = co.chat(\n",
        "    model=\"command-r-plus-08-2024\", # this is a cohere model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Write a short summary (100 characters at max), in Italian of the textual article \\\n",
        "            provided below: \\n\\n {}\".format(response.objects[0].properties[\"maintext\"]),\n",
        "        } # response includes all the results returned by the previous hybrid query\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(res.message.content[0].text)"
      ],
      "metadata": {
        "id": "TSQQHbw0C_7m",
        "outputId": "226957ca-1c54-4b6c-d8e9-533ea4bf5f4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conte nega l'interesse del Chelsea per Sanchez, mentre il Norwich si prepara per la sfida.\n"
          ]
        }
      ]
    }
  ]
}